# ext/LandmarkSelectExt.py
# -----------------------------------------------------------------------------
# LandmarkSelectExt
# orig generated by ChatGPT. it has errors and odd naming etc.
# -----------------------------------------------------------------------------
# Purpose
#   Lives on the child COMP 'landmarkSelect'. It:
#     1) Reads the current LandmarkFilter (menu key) and Landmarkfiltercsv (file).
#     2) Iterates LandmarkFilterMenu_csv (key,label,csv) to resolve the mask CSV
#        for the selected key.
#     3) Sets landmark_mask.par.file based on that resolution:
#          - key == 'all'    -> ''
#          - key == 'custom' -> Landmarkfiltercsv (user file)
#          - else            -> csv value from LandmarkFilterMenu_csv
#     4) Builds a Select CHOP channel pattern:
#          - 'all'  : expand every 'name' in landmark_names -> name_x/y/z
#          - others : read landmark_mask rows; accept 'chan' or 'name'
#     5) Writes the space-separated list to select1.par.channame
#
# Assumptions
#   - Channels are UNPREFIXED, e.g., 'wrist_l_x'.
#   - Inside 'landmarkSelect' you have:
#       * landmark_names         (Table DAT)  with column 'name'
#       * landmark_mask          (Table DAT)  file switched here
#       * LandmarkFilterMenu_csv (Table DAT)  with columns key,label,csv
#       * select1                (Select CHOP) targeting ../in1
#       * outCHOP                (Null CHOP)   pass-through
#   - Parameters on this COMP:
#       * LandmarkFilter     (menu token)
#       * Landmarkfiltercsv  (file; used when key == 'custom')
# -----------------------------------------------------------------------------

class LandmarkSelectExt:
    def __init__(self, owner):
        self.owner = owner

    # Public entry point -------------------------------------------------------
    def Rebuild(self):
        """
        Resolve mask file from LandmarkFilterMenu_csv and rebuild the Select CHOP.
        """
        key = (self.owner.par.LandmarkFilter.eval() or '').strip().lower()
        custom_csv = (self.owner.par.Landmarkfiltercsv.eval() or '').strip()

        sel       = self.owner.op('select1')
        mask      = self.owner.op('landmark_mask')
        menu_tab  = self.owner.op('LandmarkFilterMenu_csv')
        names_tab = self.owner.op('landmark_names')

        if not sel or not mask or not menu_tab or not names_tab:
            self._log("Missing ops (select1/landmark_mask/LandmarkFilterMenu_csv/landmark_names).")
            return

        # -- 1) Iterate menu table to find the default CSV for this key ----------
        # This is where all non-('all'|'custom') keys are resolved.
        default_csv = self._lookup_csv(menu_tab, key)

        # -- 2) Choose which file drives 'landmark_mask' -------------------------
        if key in ('', 'all'):
            mask.par.file = ''                # not used; we'll expand from names
        elif key == 'custom':
            mask.par.file = custom_csv        # user-provided file
        else:
            mask.par.file = default_csv or '' # could be empty; that's allowed

        # -- 3) Build the channel list -------------------------------------------
        if key in ('', 'all'):
            # Expand every landmark name to *_x/_y/_z
            names = _col_as_list(names_tab, 'name')
            chan_list = _flatten([_expand_xyz(n) for n in names])
        else:
            # Use rows from the selected mask CSV (supports 'chan' or 'name')
            rows = _rows_as_dicts(mask)
            chan_list = []
            for r in rows:
                ch = (r.get('chan') or '').strip()
                nm = (r.get('name') or '').strip()
                if ch:
                    chan_list.append(ch)          # verbatim (wildcards OK)
                elif nm:
                    chan_list += _expand_xyz(nm)

        # -- 4) Apply to the Select CHOP -----------------------------------------
        final = _dedup(chan_list)
        sel.par.op = '../in1'
        sel.par.channame = ' '.join(final)

        self._log(f"Rebuild key='{key}', patterns={len(final)}, mask='{mask.par.file.eval()}'")

    # Helpers ------------------------------------------------------------------
    def _lookup_csv(self, tableDAT, key):
        """
        Iterate LandmarkFilterMenu_csv to find the CSV path for 'key'.
        Returns '' if not found or column missing.

        Table schema (case-insensitive headers):
          key, label, csv
        """
        if not tableDAT or tableDAT.numRows < 2:
            return ''
        headers = [c.val.lower() for c in tableDAT.row(0)]
        try:
            key_i = headers.index('key')
            csv_i = headers.index('csv')
        except ValueError:
            return ''
        for r in tableDAT.rows()[1:]:
            if r[key_i].val.strip().lower() == key:
                return (r[csv_i].val or '').strip()
        return ''

    def _log(self, msg):
        logdat = self.owner.op('log')
        try:
            if logdat and hasattr(logdat, 'write'):
                logdat.write(str(msg) + '\n')
            else:
                print(str(msg))
        except Exception:
            pass


# Module helpers ---------------------------------------------------------------
def _rows_as_dicts(tab):
    try:
        if tab.numRows <= 1 or tab.numCols <= 0:
            return []
        heads = [c.val.lower() for c in tab.row(0)]
        out = []
        for r in tab.rows()[1:]:
            d = {}
            for i in range(min(len(heads), len(r))):
                d[heads[i]] = r[i].val
            out.append(d)
        return out
    except Exception:
        return []

def _col_as_list(tab, colname):
    try:
        if tab.numRows <= 1 or tab.numCols <= 0:
            return []
        heads = [c.val.lower() for c in tab.row(0)]
        if colname.lower() not in heads:
            return []
        ci = heads.index(colname.lower())
        return [r[ci].val.strip() for r in tab.rows()[1:] if r[ci].val.strip()]
    except Exception:
        return []

def _expand_xyz(name):
    base = f"{name}_"
    return [base + 'x', base + 'y', base + 'z']

def _dedup(seq):
    seen, out = set(), []
    for s in seq:
        if s and s not in seen:
            seen.add(s); out.append(s)
    return out

def _flatten(xx):
    out = []
    for sub in xx:
        out.extend(sub)
    return out

