# /ext/LandmarkSelectExt.py
# -----------------------------------------------------------------------------
# LandmarkSelectExt
# -----------------------------------------------------------------------------
# will log to logger
# High-level purpose
# ------------------
# This extension lives on the `landmarkSelect` COMP. It builds a list of CHOP
# channel names (patterns) to feed into a Select CHOP based on user parameters:
#   - Landmarkfilter: All | Hands | BasicPose | Face | CustomCSV
#   - Filtercsv:  Path to a user CSV (used only when Landmarkfilter=CustomCSV)
#
# the script is referenced by a Text DAT called LandmarkSelectExt
# and the COMP's Extension Object is op('./LandmarkSelectExt').module.LandmarkSelectExt(me)
#
# Supported CSV schemas in data/
# ---------------------
# - landmark_names.csv:       header has 'name' (case-insensitive)
# - masks_*.csv / custom.csv: either 'name' (landmark names) or 'chan'
#                              * 'name'  -> expanded to p{pid}_name_x/y/z
#                              * 'chan'  -> used verbatim (wildcards allowed)
#
# Safety & ergonomics
# -------------------
# - Robust to missing files/columns (logs + no-throw)
# - De-duplicates while preserving order
# - Does not hard-crash if an operator is missing; logs and returns
# - Centralized logging helper that writes to a sibling 'log' Text DAT if present
#
# Integration points
# ------------------
# - Call `ext.LandmarkSelectExt.Rebuild()` when Landmarkfilter/Filtercsv/Personid
#   changes, or from PoseEffectExt.ApplyFilter().
# - Exposes small helpers for reading tables, expanding names, and logging.
# -------
# orig generated by ChatGPT. it has errors and odd naming etc.
# table_names table_mask etc are inherited architecturally from LandmarkSelect design
# but should be better named landmark_names Landmark_mask or such (TODO)
# -----------------------------------------------------------------------------


class LandmarkSelectExt:
    """Extension attached to the `landmarkSelect` COMP. (re)builds Select CHOP channel patterns. See header for details."""

    # ------------------------------
    # Lifecycle / plumbing
    # ------------------------------
    def __init__(self, owner):
        """
        owner: the `landmarkSelect` COMP this extension is bound to.
        """
        self.owner = owner

    # ------------------------------
    # Public API
    # ------------------------------
    def Rebuild(self):
        """
        Recompute the landmark selection with a Switch-CHOP pass-through strategy.

        Behavior
        --------
        - If Landmarkfilter is empty, "all", or "*":
            * Do NOT build any pattern string or read CSVs.
            * Route pass-through: switch1.index = 0
            * Bypass select1 to avoid unnecessary cooking.
            * Return early.
        - Otherwise:
            * Resolve the CSV path for the chosen filter (or use override CSV parameter).
            * Load that CSV into the 'landmark_mask' Table DAT.
            * Build the channel list (expanding 'name' rows to *_x/_y/_z; 'chan' rows used verbatim).
            * Deduplicate (preserve order).
            * Ensure select1 has a valid source (prefer wired input; otherwise set par.chop to ../in1).
            * Write channames (only if changed).
            * Route filtered path: switch1.index = 1 and un-bypass select1.

        Robustness
        ----------
        - Logs and returns if required OPs are missing (select1, switch1, in1, landmark_mask).
        - Parameter names are checked in a tolerant way (Landmarkfilter vs LandmarkFilter, etc.).
        - Only writes TD parameters when values change to avoid cook dependency loops.
        """

        par = self.owner.par

        # --- param helpers (tolerant to naming) -----------------------------------
        def _get_str(par_names, default=''):
            for n in par_names:
                if hasattr(par, n):
                    try:
                        v = getattr(par, n).eval()
                    except Exception:
                        v = getattr(par, n)
                    return (v or '').strip()
            return default

        mode = _get_str(('Landmarkfilter', 'LandmarkFilter')).lower()
        csv_override = _get_str(('Landmarkfiltercsv', 'LandmarkMaskCSV'))

        # --- op handles ------------------------------------------------------------
        sel = self.owner.op('select1')
        sw  = self.owner.op('switch1')
        in1 = self.owner.op('in1')
        tmask = self.owner.op('landmark_mask')

        if not sel or not sw or not tmask:
            self._log("[Rebuild] ERROR: missing one of required ops: select1 / switch1 / landmark_mask.")
            return
        if not in1:
            # We can still function if select1 has a wire, but warn once.
            self._log("[Rebuild] WARNING: 'in1' not found in landmarkSelect; will rely on wired input to select1.")

        # --- PASS-THROUGH for All/blank -------------------------------------------
        if mode in ('', 'all', '*'):
            # Route pass-through (input 0) and bypass select
            if sw.par.index.eval() != 0:
                sw.par.index = 0
            if not sel.bypass:
                sel.bypass = True
            self._log("[Rebuild] Pass-through path (All). switch1.index=0, select1.bypass=1.")
            return

        # --- resolve CSV path for filtered modes ----------------------------------
        csv_path = ''
        if mode == 'hands':
            csv_path = 'data/masks_hands.csv'
        elif mode == 'basicpose':
            csv_path = 'data/masks_basicpose.csv'
        elif mode == 'face':
            csv_path = 'data/masks_face.csv'
        elif mode in ('customcsv', 'custom'):
            csv_path = csv_override
            if not csv_path:
                self._log("[Rebuild] CustomCSV selected but no CSV override provided.")
        else:
            # Unknown mode: treat as filtered-but-misconfigured → fallback to pass-through
            self._log(f"[Rebuild] Unknown Landmarkfilter '{mode}'. Using pass-through.")
            if sw.par.index.eval() != 0:
                sw.par.index = 0
            if not sel.bypass:
                sel.bypass = True
            return

        if not csv_path:
            # Filtered mode but no csv_path resolved → safe fallback to pass-through
            self._log(f"[Rebuild] No CSV found for mode '{mode}'. Using pass-through.")
            if sw.par.index.eval() != 0:
                sw.par.index = 0
            if not sel.bypass:
                sel.bypass = True
            return

        # --- load CSV into landmark_mask ------------------------------------------
        try:
            if tmask.par.file.eval() != csv_path:
                tmask.par.file = csv_path
            # Reload to be explicit
            if hasattr(tmask.par, 'reload'):
                tmask.par.reload.pulse()
        except Exception as e:
            self._log(f"[Rebuild] ERROR setting landmark_mask file: {e}")
            return

        # --- build channel list from mask rows ------------------------------------
        items = self._read_mask_items()
        if not items:
            self._log(f"[Rebuild] No rows read from mask '{csv_path}'. Using pass-through.")
            if sw.par.index.eval() != 0:
                sw.par.index = 0
            if not sel.par.bypass:
                sel.par.bypass = True
            return

        channels = []
        for kind, val in items:
            if kind == 'chan':
                channels.append(val)
            else:
                channels += self._expand_name_to_chans(val)

        final = _dedup_preserve_order(channels)
        pattern = ' '.join(final)

        # --- ensure select1 has a source ------------------------------------------
        # Prefer wire. If wired, clear par.chop; else set it to ../in1 if available.
        if sel.inputs and len(sel.inputs) > 0:
            if sel.par.chop.eval() != '':
                sel.par.chop = ''
        else:
            # fall back to parent-in1 if not wired
            fallback_src = self.owner.parent().op('in1') or in1
            if fallback_src:
                if sel.par.chop.eval() != fallback_src.path:
                    sel.par.chop = fallback_src.path
            else:
                self._log("[Rebuild] No wired input and no '../in1' available; cannot apply filter.")
                return

        # --- write channames only if changed --------------------------------------
        try:
            if sel.par.channames.eval() != pattern:
                sel.par.channames = pattern
        except Exception as e:
            self._log(f"[Rebuild] ERROR writing channames: {e}")
            return

        # --- switch to filtered path and un-bypass select --------------------------
        if sw.par.index.eval() != 1:
            sw.par.index = 1
        if sel.par.bypass:
            sel.par.bypass = False

        self._log(f"[Rebuild] Filter='{mode}', {len(final)} chans → switch1.index=1.")

    # ------------------------------
    # Helpers (table reads / transforms)
    # ------------------------------
    def _read_landmark_names(self):
        """
        Read `landmark_names` and return a list of landmark names (strings).
        Accepts any header casing; expects a 'name' column.
        that op should be DAT that loads data/landmark_names.csv
        a table of id, name
        """
        tnames = self.owner.op('landmark_names')
        if not tnames:
            self._log("[_read_landmark_names] Missing 'landmark_names' Table DAT.")
            return []
        rows = _rows_dicts(tnames)
        names = []
        for row in rows:
            nm = (row.get('name') or row.get('landmark') or '').strip()
            if nm:
                names.append(nm)
        if not names:
            self._log("[_read_landmark_names] No 'name' values found.")
        return names

    def _read_mask_items(self):
        """
        Read `table_mask` and return a list of tuples:
          - ('chan', <pattern or full channel>)
          - ('name', <landmark name>)
        Either column may be present; both can be mixed per-row. Case-insensitive.
        """
        tmask = self.owner.op('landmark_mask')
        if not tmask:
            self._log("[_read_mask_items] Missing 'table_mask' Table DAT.")
            return []
        rows = _rows_dicts(tmask)
        items = []
        for row in rows:
            ch = (row.get('chan') or '').strip()
            nm = (row.get('name') or '').strip()
            if ch:
                items.append(('chan', ch))
            elif nm:
                items.append(('name', nm))
        return items

    def _expand_name_to_chans(self, name):
        """
        Given a landmark name and person id, produce TouchDesigner CHOP channel
        names for axes x/y/z (z is included for forward compatibility).
        Example: name='wrist_l', pid=1 -> ['p1_wrist_l_x', 'p1_wrist_l_y', 'p1_wrist_l_z']
        """
        base = f"{name}_"
        # Even if you don't currently publish _z, including it here is harmless:
        # the Select CHOP will simply ignore non-existent channels.
        return [base + 'x', base + 'y', base + 'z']

    # ------------------------------
    # Logging
    # ------------------------------
    def _log(self, msg):
        """
        Write to a sibling 'log' Text DAT if present, else print to TD textport.
        """
        logdat = self.owner.op('log')
        try:
            if logdat and hasattr(logdat, 'write'):
                logdat.write(str(msg) + '\n')
            else:
                print(str(msg))
        except Exception:
            # Avoid throwing from logging
            pass


# -----------------------------------------------------------------------------
# Module-level utilities (no TD state needed)
# -----------------------------------------------------------------------------
def _rows_dicts(tab):
    """
    Convert a Table DAT to a list of dicts using row 0 as header (case-insensitive).
    Returns [] if fewer than 2 rows or no columns.
    """
    try:
        if tab.numRows <= 1 or tab.numCols <= 0:
            return []
        headers = [c.val.lower() for c in tab.row(0)]
        out = []
        for r in tab.rows()[1:]:
            d = {}
            # min() prevents index errors if rows are ragged
            for i in range(min(len(headers), len(r))):
                d[headers[i]] = r[i].val
            out.append(d)
        return out
    except Exception:
        return []


def _dedup_preserve_order(seq):
    """
    De-duplicate while preserving input order.
    """
    seen = set()
    out = []
    for item in seq:
        if item and item not in seen:
            seen.add(item)
            out.append(item)
    return out


def _safe_int(par, default):
    """
    Safely coerce a parameter to int; returns `default` on failure.
    """
    try:
        return int(par)
    except Exception:
        try:
            return int(par.eval())
        except Exception:
            return int(default)
